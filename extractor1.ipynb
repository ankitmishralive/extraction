{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -U pypdfium2\n",
    "# # install package\n",
    "# !pip install -U langchain-ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install matplotlib\n",
    "# !pip install pillow\n",
    "# !pip install pdf2image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All images saved in: pdf3/\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import fitz  # PyMuPDF\n",
    "\n",
    "def convert_pdf_to_img(pdf_path, drop_location):\n",
    "    # Extract the PDF name without extension\n",
    "    pdf_name = os.path.splitext(os.path.basename(pdf_path))[0]\n",
    "    \n",
    "    # Ensure the drop location exists\n",
    "    os.makedirs(drop_location, exist_ok=True)\n",
    "    \n",
    "    # Open the PDF\n",
    "    doc = fitz.open(pdf_path)\n",
    "    \n",
    "    image_paths = []\n",
    "    for i, page in enumerate(doc, start=1):\n",
    "        # Generate image from page\n",
    "        pix = page.get_pixmap()\n",
    "        \n",
    "        # Save the image as {pdf_name}_1.png, {pdf_name}_2.png, etc.\n",
    "        img_path = os.path.join(drop_location, f\"{i}.png\")\n",
    "        pix.save(img_path)\n",
    "        image_paths.append(img_path)\n",
    "    \n",
    "    print(f\"All images saved in: {drop_location}\")\n",
    "\n",
    "# Example usage\n",
    "pdf_path = \"3.pdf\"           # Path to your PDF file\n",
    "drop_location = \"pdf3/\"      # Folder where files should be saved\n",
    "convert_pdf_to_img(pdf_path, drop_location)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### --- OCR ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pytesseract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytesseract import image_to_string \n",
    "from PIL import Image\n",
    "from io import BytesIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted Text:\n",
      " i\n",
      "\n",
      "aT\n",
      "\n",
      "PATIENT NAME : VAISHALI VAY BELLUBBI\n",
      "\n",
      "TameNTID: #H.3991490) {QUENT PATENT 19: W380\n",
      "AecasSion NO: 9081XDO12004 Act; 6OYeHrs Sex: Female DATEOF RTH: 26/02/1956\n",
      "Dawn: 16/04/2026 02:36 ecerven: 16/04/2026 05:55 ePORTED: 16/04/2024 07:06\n",
      "CQHENTRUNE = FHSL BG ROAD-190 REFERRING DOCTOR: OR. Rajpal RL. Singh\n",
      "\n",
      "p:3981490 REQNO-17006613,\n",
      "Wow ceutcieu\n",
      "‘ab-ses10/24/1113\n",
      "\n",
      "(axmmnew sad = capa ners erat\n",
      "\n",
      "(£8625. EDTA WHOLE BLOOD\n",
      "\n",
      "+ BL000 COUNTS, EDTA WHOLE BLOOD\n",
      "\n",
      "HenOG.oBIN (HB) 3 120-150 va.\n",
      "\n",
      "RED BLOOD CELL (RBC) COUNT 43 38-48 mv,\n",
      "\n",
      "\\WnITE at000 CEL. (w8C) COUNT 896 40-100 mow\n",
      "\n",
      "PLATELET COUNT ss tow 180-410 thou\n",
      "NETIC: AMOMTED aL COATED PRUE FONE (OC OTECION)\n",
      "\n",
      "[RATELET COUNT COMTRMED ON SHEAR\n",
      "‘Rac ANO PLATELET INDICES\n",
      "\n",
      "reaToen Po as 46 *\n",
      "MEM CORPUSCIUR VOUME DIC) #22 lm 29-1010 8\n",
      "em CORPUSCIOR WEMOGLONNGHCH) 277 no-no =\n",
      "we comuscuua wenoctoa 237 nisms wa\n",
      "\n",
      "CONCENTRATION)\n",
      "\n",
      "RED CEL DISTRIBUTION WIDTH (ROW) 2 116-140 *\n",
      "MENTZER INDEX va\n",
      "MEAN PLATELET VOLUME (HPV) ns\n",
      "Wac DIFFERENTIAL COUNT\n",
      "\n",
      "NEUTROPHILS 2 40-80 *\n",
      "LmpHocrTes. 2 20-40 *\n",
      "mowocres ° 2-10 *\n",
      "OsINomHILs 1 1-6 *\n",
      "\n",
      "\n",
      "allure, 7\n",
      "\n",
      "PATIENT NAME : VAISHALI VAY BELLUBBE\n",
      "\n",
      "anew: pH.3901490 ‘cpa 10  utoave14e\n",
      "ACCESSIONNO: 0QBIXDO12006 AGE: 68'Yeors SEX: Ferble OATEOFBINH: 26/02/1956\n",
      "awn: 16/04/2024 02:36 necEIVED + 16/04/2024 05:55 seronreD : 16/04/2028 07:06\n",
      "QUENT RHE | ASL NG ROAD -190, REFERRING DOCTOR: OR, Raja! RL. Sigh\n",
      "\n",
      "\\io:3991490 REQNO-17006613\n",
      "ors ceut (icy\n",
      "no-80910/24/1113,\n",
      "\n",
      "free Reor stator Final = eto etree tral une\n",
      "sons 0 <a *\n",
      "sesouire nero coe sa 20-79 oun\n",
      "sesouire comocrte count co to-20 tuna\n",
      "sasouinevenoome cunt a e2-19 wou\n",
      "sesouiTe osinomaL COT OOD 002-050 oun\n",
      "sesoume scone CONT 0.00 tne 002-010 wou\n",
      "veuraonc mmo AO Oa)\n",
      "\n",
      "EROS meres eter nae MCUR) on erate coated ed sou a ete ef ren eee sen)\n",
      "\n",
      "optus, SERUM 140 6-5 met\n",
      "\n",
      "POTASSIUM, SERUM 383 35-54 mmol\n",
      "\n",
      "‘CHLORIDE, SERUM 108 Wien 96-107 meu\n",
      "\n",
      "‘CREATININE EGER- EPI\n",
      "\n",
      "‘CREATININE 097 Mion 05-09 mara.\n",
      "\n",
      "Me “ eons\n",
      "\n",
      "‘GLOMERULAR FILTRATION RATE (FEMALE) e365 afer Interpretation Selon mi/min/3.73m2\n",
      "“ghee ingens 28> Page 2064\n",
      "\n",
      "Pepacrnentns\n",
      "Sooner\n",
      "\n",
      "sao. vt\n",
      "\n",
      "\n",
      "PATIENT NAME : VAISHALE VIIAY BELLUBBI\n",
      "\n",
      "PmIeNTiD: FH.9991490) ‘GHENT PATIENT 1 UD-291680,\n",
      "ACCESSIONNO: 0081XD012008 AGE) 68 Yeurs Sex: Female OATEOF HTN: 26/02/1986\n",
      "aan: 16/04/2026 02:36, neceneD: 16/04/2028 05:55 eroRTED : 16/04/20 07:06\n",
      "QUENT RIE + FHSL.BG ROAD-290 ‘REFERRING DOCTOR: OR. Ral RL Singh\n",
      "\n",
      "o3991490 quo 17006613\n",
      "os eeu Ge\n",
      "In se510/20/3813\n",
      "\n",
      "fest Report Status Final Results Biological Reference Interval__Units\n",
      "\n",
      "‘Setar tnrbo enone sesame om een be neve pase Sapo\n",
      "\n",
      "se erat a) ae Sy net)\n",
      "Seale Gedy be eum tae gee\n",
      "\n",
      "‘Sanon tn bpn of tnng caren eo Cmca angen es 221 OO Cen ry Ha 28,4307, 3628\n",
      "\n",
      "+End of Raport**\n",
      "\n",
      "Please vist agllusdlagnostics.com for related Test information fr this accession\n",
      "TEST MARKED WITH \"= ARE OUTSIDE THE NABL ACCREDITED SCOPE OF THE LABORATORY.\n",
      "\n",
      "~~ @\n",
      "\n",
      "Suet Kaur More rsinaha mayan s Or Prabal A, MO\n",
      "segs consuLTANT Canaan Paolot cong BLOC\n",
      "\n",
      "“ee feias Dagnonis tt\n",
      "ieSSomergte sate. ove,\n",
      "oop s\n",
      "\n",
      "\n",
      "=o\n",
      "\n",
      "PATIENT NAME : VAISHALI VAY BELLUBBI\n",
      "\n",
      "ogiluexe\n",
      "a\n",
      "\n",
      "paneer: FHa9B8490\n",
      "‘A<cESSION NO: 00083XD012008 AGE: 68 Years\n",
      "usw: 16/04/2028 02:36, ReceVED\n",
      "\n",
      "io: 3991490 REQNO-17006613\n",
      "Wo-tsccut acu\n",
      "hib-89910/24/1113,\n",
      "\n",
      "sox: Femole ore ormiem: 25/02/1956\n",
      "16/08/2028 05:55\n",
      "\n",
      "REPORTED: 16/04/2026 07:06\n",
      "\n",
      "[REFERRING DOCTOR : OR. Rajpal RL. Singh\n",
      "\n",
      "[Test Report Status inal\n",
      "\n",
      "Biological Reference Interval Units\n",
      "\n",
      "nomad or enti nthe test requatton frm.\n",
      "2° tests are perormed ad reported 2 per the\n",
      "tenaroune tine stated i the AILUS Directory of Services.\n",
      "mess delays could ccrur due to unforeseen\n",
      "reumetaneer such ae non-avaibiny of Hs / equlement\n",
      "breakdown / natural alanis / technica downame or any\n",
      "other unfoessen event.\n",
      "A requested test might not be performed if\n",
      "\n",
      "{Specimen received ' insfcent or inappropriate\n",
      "\n",
      "1, Specimen qualty is unsotisfectory\n",
      "\n",
      "Wi Incorrect specimen type\n",
      "\n",
      "Te presumed that the Test sample belongs tothe patent\n",
      "\n",
      "'3._AGILUS Diagnosis confrtns Hata tess have Dean\n",
      "Berfrmed or assayed with highest quay stander, circa\n",
      "\n",
      "determine fal dagnoss.\n",
      "17. “Test results may vary based on time of ealection,\n",
      "‘hysologicalcondton of the patient, current mediation or\n",
      "rutritonal and etary changes. Pease consu your doctor oF\n",
      "{al os for any reson\n",
      "\n",
      "i. Test resus cannot be used fr Medico legal purposes.\n",
      "9. Incase of queries please call customer care\n",
      "\n",
      "(1115 91115) warn 48 hours ofthe repo.\n",
      "\n",
      "* hates agnostics Limite\n",
      "fe gay Sor, Pe,\n",
      "\n",
      "T. Patent ery and demographic detals are crucial for 2\n",
      "esrect report. Kay check your Name / Age 7 Mabie\n",
      "umber & Email 1 on the test equsiton form and receipt.\n",
      "\n",
      "2 n case of calcd spacimen(s) refered to AGILUS /\n",
      "catectea by satires prosumed thatthe same belongs\n",
      "tothe patient named or enti in the test requstion\n",
      "tcc. Te referring Lab feaiecion authorey I response\n",
      "to aperpriate sample colecuon os per pre-requisites,\n",
      "oben ana anspor.\n",
      "\n",
      "3. Atresn sample may be requested if the Qualty or\n",
      "|quonty of received same i unsatsfacory\n",
      "\n",
      "‘5. Kindly share a encal eta along withthe specimen for\n",
      "‘sccurate dagnoss, AGILUS Diagnosis may request for\n",
      "‘datonolnormation for cimcal ce-elton a= & when\n",
      "requred\n",
      "\n",
      "6. Tests once regitered cannat be CANCELLED!\n",
      "\n",
      "‘har Dlognostcs Lite\n",
      "fac ey Ser Poe I\n",
      "\n",
      "“Betas ments >\n",
      "ish omens tse\n",
      "\n",
      "Sat ope.\n",
      "Sire, 76\n",
      "\n",
      "Page 4.0F4\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "from pytesseract import image_to_string\n",
    "\n",
    "def extract_text_from_images(folder_path):\n",
    "    \"\"\"\n",
    "    Extracts text from all images in the specified folder.\n",
    "    Processes images in numeric sequence if they are named accordingly.\n",
    "    \n",
    "    Args:\n",
    "        folder_path (str): Path to the folder containing images.\n",
    "    \n",
    "    Returns:\n",
    "        str: Combined text extracted from all images.\n",
    "    \"\"\"\n",
    "    # List all files in the folder and sort them numerically (e.g., 1.png, 2.png)\n",
    "    image_files = sorted(\n",
    "        [f for f in os.listdir(folder_path) if f.lower().endswith(('.png', '.jpg', '.jpeg'))],\n",
    "        key=lambda x: int(os.path.splitext(x)[0])  # Extract numeric part for sorting\n",
    "    )\n",
    "    \n",
    "    image_content = []\n",
    "    \n",
    "    for image_file in image_files:\n",
    "        image_path = os.path.join(folder_path, image_file)\n",
    "        \n",
    "        # Open the image file\n",
    "        image = Image.open(image_path)\n",
    "        \n",
    "        # Use Tesseract to extract text\n",
    "        raw_text = image_to_string(image)\n",
    "        image_content.append(raw_text)\n",
    "    \n",
    "    # Join all extracted text with newline separators\n",
    "    return \"\\n\".join(image_content)\n",
    "\n",
    "# Example usage\n",
    "folder_path = \"pdf3\"  # Path to the folder containing images\n",
    "extracted_text_pytessract = extract_text_from_images(folder_path)\n",
    "print(\"Extracted Text:\\n\", extracted_text_pytessract)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from PIL import Image\n",
    "# from pytesseract import image_to_string\n",
    "# from io import BytesIO\n",
    "\n",
    "# def extract_text_with_pytesseract(image_source):\n",
    "#     \"\"\"\n",
    "#     Extracts text from images using Tesseract OCR.\n",
    "    \n",
    "#     Parameters:\n",
    "#     - image_source (str or list): A file path to a single image or a list of image bytes.\n",
    "\n",
    "#     Returns:\n",
    "#     - str: Extracted text from the image(s).\n",
    "#     \"\"\"\n",
    "#     image_content = []\n",
    "\n",
    "#     if isinstance(image_source, str):  # Single image file path\n",
    "#         image = Image.open(image_source)\n",
    "#         raw_text = str(image_to_string(image))\n",
    "#         image_content.append(raw_text)\n",
    "\n",
    "#     elif isinstance(image_source, list):  # List of image byte dictionaries\n",
    "#         image_list = [list(data.values())[0] for data in image_source]\n",
    "#         for index, image_bytes in enumerate(image_list):\n",
    "#             image = Image.open(BytesIO(image_bytes))\n",
    "#             raw_text = str(image_to_string(image))\n",
    "#             image_content.append(raw_text)\n",
    "\n",
    "#     else:\n",
    "#         raise ValueError(\"Invalid input type. Provide a single file path or a list of dictionaries with image bytes.\")\n",
    "\n",
    "#     return \"\\n\".join(image_content)\n",
    "\n",
    "\n",
    "# # Example Usage with a Single Image File\n",
    "# pdf1 = \"1.png\"\n",
    "# text_with_pytesseract = extract_text_with_pytesseract(pdf1)\n",
    "# print(text_with_pytesseract)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama.llms import OllamaLLM\n",
    "from langchain.output_parsers import ResponseSchema, StructuredOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "\n",
    "llm= OllamaLLM(model=\"llama3.1:latest\")\n",
    "\n",
    "def convert_text_to_json_with_llm(extracted_text):\n",
    "    \"\"\"\n",
    "    Uses an LLM to convert extracted text into JSON format.\n",
    "    \n",
    "    Parameters:\n",
    "    - extracted_text (variable): A  detail text information identifiers and extracted text.\n",
    "\n",
    "    Returns:\n",
    "    - str: A JSON string with structured key-value pairs of every extracted information\n",
    "    \"\"\"\n",
    "    prompt =  f\"Return All textual Data in key Value Pair in JSON:\\n{extracted_text}\"\n",
    "\n",
    "    response = llm(prompt)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "structured_json = convert_text_to_json_with_llm(extracted_text_pytessract)\n",
    "\n",
    "print(structured_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_10887/1066867024.py:44: LangChainDeprecationWarning: The method `BaseLLM.__call__` was deprecated in langchain-core 0.1.7 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  response = llm(formatted_prompt)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Patient': {'Name': 'VAISHALI VAY BELLUBBI', 'Age': '68 Years', 'Gender': 'Female'}, 'Accession Numbers': ['00083XD012008', '00083XD012008', '00083XD012008'], 'Test Requested': {'Sample ID': '3991490', 'Request Number': '17006613', 'Date': '16/04/2028 02:36', 'Reception Date': '16/08/2028 05:55', 'Reported Date': '16/04/2026 07:06'}, 'Test Results': {'Status': 'Final', 'Biological Reference Interval Units': [{'Name': '', 'Units': ''}]}, 'Referring Doctor': {'Name': 'OR. Rajpal RL. Singh'}, 'Notes': {'Message': 'Please visit agillusdiagnostics.com for related test information for this accession.', 'Disclaimer': ['Test marked with \"=\" are outside the NABL accredited scope of the laboratory.', 'Sample received insufficient or inappropriate.', 'Specimen quality is unsatisfactory.', 'Incorrect specimen type.', 'Presumed that the Test sample belongs to the patient.', 'Test results may vary based on time of election, physiological condition of the patient, current medication or nutritional and dietary changes. Please consult your doctor or lab for any reason.', 'Test results cannot be used for Medico legal purposes.', 'In case of queries please call customer care (1115 91115) within 48 hours of the report.']}, 'Additional Information': {'Message': ['Please check your Name / Age & Mobie number & Email on the test question form and receipt.', 'Atresn sample may be requested if the Quality or Quantity of received same is unsatisfactory.', 'Kindly share a encal eta along with the specimen for accurate diagnosis, AGILUS Diagnosis may request for datanormation for clinical evaluation & when required.']}}\n"
     ]
    }
   ],
   "source": [
    "from langchain_ollama.llms import OllamaLLM\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "import json\n",
    "\n",
    "def convert_text_to_json_with_llm(input_text):\n",
    "    \"\"\"\n",
    "    Converts any input text into a structured JSON format.\n",
    "    \n",
    "    Parameters:\n",
    "    - input_text (str): Any text input to be converted to JSON\n",
    "    \n",
    "    Returns:\n",
    "    - str: A JSON string containing structured data\n",
    "    \"\"\"\n",
    "    # Create a generic prompt template for JSON conversion\n",
    "    template = \"\"\"\n",
    "    Convert the following text into a proper JSON format.\n",
    "    Extract all relevant information as key-value pairs.\n",
    "    Return ONLY a valid JSON object, nothing else.\n",
    "    \n",
    "    Text to convert:\n",
    "    {text}\n",
    "    \n",
    "    Rules:\n",
    "    1. Structure all information into logical key-value pairs\n",
    "    2. Group related information together\n",
    "    3. Use arrays for multiple related items\n",
    "    4. Maintain proper JSON syntax\n",
    "    5. Return only the JSON object with no additional text or explanation\n",
    "    \"\"\"\n",
    "    \n",
    "    prompt = PromptTemplate(\n",
    "        template=template,\n",
    "        input_variables=[\"text\"]\n",
    "    )\n",
    "    \n",
    "    # Initialize the LLM\n",
    "    llm = OllamaLLM(model=\"llama3.1:latest\")\n",
    "    \n",
    "    # Generate the formatted prompt\n",
    "    formatted_prompt = prompt.format(text=input_text)\n",
    "    \n",
    "    # Get response from LLM\n",
    "    response = llm(formatted_prompt)\n",
    "    \n",
    "    try:\n",
    "        # Clean the response\n",
    "        cleaned_response = response.strip()\n",
    "        # Find JSON boundaries\n",
    "        start_idx = cleaned_response.find('{')\n",
    "        end_idx = cleaned_response.rfind('}')\n",
    "        \n",
    "        if start_idx != -1 and end_idx != -1:\n",
    "            cleaned_response = cleaned_response[start_idx:end_idx + 1]\n",
    "            \n",
    "            # Parse and validate JSON\n",
    "            parsed_json = json.loads(cleaned_response)\n",
    "            \n",
    "            # Return formatted JSON string\n",
    "            return json.dumps(parsed_json, indent=2, ensure_ascii=False)\n",
    "        else:\n",
    "            raise ValueError(\"No valid JSON object found in response\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        raise Exception(f\"Failed to parse LLM output into JSON: {str(e)}\")\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "try:\n",
    "        json_output = convert_text_to_json_with_llm(extracted_text_pytessract)\n",
    "        json_output = json.loads(json_output)\n",
    "        print(json_output)\n",
    "except Exception as e:\n",
    "        print(f\"Error: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(json_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EasyOCR "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install easyocr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from easyocr import Reader\n",
    "\n",
    "# Load model for the English language\n",
    "language_reader = Reader([\"en\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "from easyocr import Reader\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "def extract_text_with_easyocr(file_path):\n",
    "    # Initialize EasyOCR reader\n",
    "    language_reader = Reader(['en'], gpu=True)  # Adjust language or GPU usage as needed\n",
    "    \n",
    "    # Open the image file\n",
    "    image = Image.open(file_path)\n",
    "    \n",
    "    # Convert the image to a NumPy array\n",
    "    image_np = np.array(image)\n",
    "    \n",
    "    # Read text using EasyOCR\n",
    "    raw_text = language_reader.readtext(image_np, detail=0)  # `detail=0` returns only the text\n",
    "    raw_text = \"\\n\".join(raw_text)\n",
    "    \n",
    "    return raw_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf1 = \"1.png\"\n",
    "text_with_easyocr = extract_text_with_easyocr(pdf1)\n",
    "print(text_with_easyocr)\n",
    "\n",
    "try:\n",
    "        json_output_easyocr = convert_text_to_json_with_llm(text_with_easyocr)\n",
    "        json_output_easyocr = json.loads(json_output_easyocr)\n",
    "        print(json_output_easyocr)\n",
    "except Exception as e:\n",
    "        print(f\"Error: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(json_output_easyocr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf1 = \"1.png\"\n",
    "text_with_pytesseract = extract_text_with_pytesseract(pdf1)\n",
    "print(text_with_pytesseract)\n",
    "\n",
    "try:\n",
    "        json_output_pytesseract = convert_text_to_json_with_llm(text_with_pytesseract)\n",
    "        json_output_pytesseract = json.loads(json_output_pytesseract)\n",
    "        print(json_output_pytesseract)\n",
    "except Exception as e:\n",
    "        print(f\"Error: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(json_output_pytesseract)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(json_output_easyocr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### --------- Langchain ---------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install langchain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install amazon-textract-caller\n",
    "# !pip install amazon-textract-textractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import AmazonTextractPDFLoader\n",
    "loader = AmazonTextractPDFLoader(\"1.pdf\")\n",
    "documents = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_community.document_loaders import AmazonTextractPDFLoader\n",
    "# loader = AmazonTextractPDFLoader(\"3.pdf\")\n",
    "# documents = loader.load()\n",
    "\n",
    "# # Multi Page Document to be on S3 Bucket "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upstage Extraction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install langchain_upstage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install python-dotenv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Now you can access the environment variable\n",
    "api_key = os.getenv(\"UPSTAGE_DOCUMENT_AI_API_KEY\")\n",
    "\n",
    "from langchain_upstage import UpstageLayoutAnalysisLoader\n",
    "\n",
    "file_path = \"3.pdf\"\n",
    "\n",
    "loader = UpstageLayoutAnalysisLoader(file_path,use_ocr=True,output_type=\"text\")\n",
    "data = loader.load()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install llama-index-readers-nougat-ocr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.readers.nougat_ocr import PDFNougatOCR\n",
    "from pathlib import Path\n",
    "\n",
    "reader = PDFNougatOCR()\n",
    "\n",
    "pdf_path = Path(\"1.png\")\n",
    "\n",
    "documents = reader.load_data(pdf_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install google-generativeai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as genai\n",
    "import os\n",
    "import base64\n",
    "\n",
    "# os.environ['GOOGLE_API_KEY']\n",
    "API_KEY = os.getenv('GOOGLE_API_KEY')\n",
    "\n",
    "# api_key = os.getenv(\"UPSTAGE_DOCUMENT_AI_API_KEY\")\n",
    "genai.configure(api_key=API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def prep_image(image_path):\n",
    "    # Upload the file and print a confirmation.\n",
    "    sample_file = genai.upload_file(path=image_path,\n",
    "                                display_name=\"Diagram\")\n",
    "    print(f\"Uploaded file '{sample_file.display_name}' as: {sample_file.uri}\")\n",
    "    file = genai.get_file(name=sample_file.name)\n",
    "    print(f\"Retrieved file '{file.display_name}' as: {sample_file.uri}\")\n",
    "    return sample_file\n",
    "\n",
    "\n",
    "def extract_text_from_image(image_path, prompt):\n",
    "    # Choose a Gemini model.\n",
    "    model = genai.GenerativeModel(model_name=\"gemini-1.5-pro\")\n",
    "    # Prompt the model with text and the previously uploaded image.\n",
    "    response = model.generate_content([image_path, prompt])\n",
    "    return response.text\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_api_key =os.getenv('GOOGLE_API_KEY')\n",
    "genai.configure(api_key=my_api_key)\n",
    "sample_file = prep_image('1.png') \n",
    "text = extract_text_from_image(sample_file, \"Extract the text in the image verbatim\")\n",
    "\n",
    "print(text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "textextraction",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
